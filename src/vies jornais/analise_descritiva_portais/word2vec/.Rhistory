source("../utils/embeddings_utils.R")
library("wordVectors")
library("readr")
noticias <- get_todas_noticias_processadas()
noticias <- get_todas_noticias_processadas()
noticias_estadao <- noticias %>% filter(subFonte == "ESTADAO")
noticias_tema <- noticias %>% filter(timestamp >= "2014-12-31" & timestamp <= "2014-12-31") %>% noticias_tema(pattern, "titulo")
tema = "eleicoes_2014_estadao_test"
limiar = 1.1
MIN_TAMANHO = 3
referencia_1 = "dilma"
referencia_2 = "aécio"
analogias <- c("pt psdb dilma", "pt pv dilma","pt prtb dilma","pt psol dilma","pt psb dilma","pt psdc dilma","psdb pv aécio","psdb prtb aécio","psdb psol aécio","psdb psb aécio","psdb psdc aécio","pv prtb jorge","pv psol jorge","pv psb jorge","pv psdc jorge","prtb psol fidelix","prtb psb fidelix","prtb psdc fidelix","psol psb luciana","psol psdc luciana","psb psdc marina","dilma aécio rousseff","campos psb aécio","pt psdb petista")
respostas <- c("aécio","jorge","fidelix","luciana","marina","eymael","jorge","fidelix","luciana","marina","eymael","fidelix","luciana","marina","eymael","luciana","marina","eymael","marina","eymael","eymael","neves","psdb","tucano")
partidos <- c("pmdb","ptb","pdt","pt","dem ","psb","psdb","ptc","psc","pmn","prp","pps","pv","pp","pstu","pcb","prtb","phs","psdc","pco","ptn","psl","prb","psol","ppl","pros","psd |psd[.]"," sd |sd[.]") #,"pr","pen", "pcdob", "ptdob"
candidatos <- c("dilma","aécio","levy","marina silva","luciana genro","eduardo jorge","josé maria","pastor everaldo", "iasi","eymael","rui costa","eduardo campos")
entity <- c(candidatos, partidos)
pattern <- paste(entity, collapse = "|")
noticias_tema <- noticias %>% filter(timestamp >= "2014-12-31" & timestamp <= "2014-12-31") %>% noticias_tema(pattern, "titulo")
noticias_tema <- noticias %>% filter(timestamp >= "2014-12-30" & timestamp <= "2014-12-31") %>% noticias_tema(pattern, "titulo")
noticias_tema <- noticias_estadao %>% filter(timestamp >= "2014-12-30" & timestamp <= "2014-12-31") %>% noticias_tema(pattern, "titulo")
source("../utils/mongo_utils.R")
source("../utils/utils.R")
source("../utils/embeddings_utils.R")
library("wordVectors")
library("readr")
noticias_tema <- noticias_estadao %>% filter(timestamp >= "2014-12-30" & timestamp <= "2014-12-31") %>% noticias_tema(pattern, "titulo")
noticias_tema <- noticias_estadao %>% filter(timestamp >= "2014-12-25" & timestamp <= "2014-12-31") %>% noticias_tema(pattern, "titulo")
source("../utils/mongo_utils.R")
source("../utils/utils.R")
source("../utils/embeddings_utils.R")
library("wordVectors")
library("readr")
noticias <- noticias_estadao %>% filter(timestamp >= "2014-12-25" & timestamp <= "2014-12-31") %>% noticias_tema(pattern, "titulo")
noticias <- noticias_estadao %>% filter(timestamp >= "2014-12-01" & timestamp <= "2014-12-31") %>% noticias_tema(pattern, "titulo")
noticias <- noticias_estadao %>% filter(timestamp >= "2014-12-01" & timestamp <= "2014-12-31") %>% noticias_tema(pattern, "titulo")
direct_bias_detection <- function(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers = 300, analogias, candidatos, entity, pattern, noticias){
train_file <- paste("saida_distancia_partidos/",tema,".csv",sep="")
binary_file <- paste("saida_distancia_partidos/",tema,".bin",sep="")
noticias_tema %>% select(conteudo_processado) %>% write_csv(train_file)
modelo <- train_word2vec(train_file, threads = 8, vectors = n_layers)
### Regras que devem ser acertadas para validar embedding
verifica_analogias(binary_file, analogias, respostas)
### Cria tsv com embedding
path_modelo_tsv = paste("saida_distancia_partidos/",tema,".tsv",sep="")
modelo@.Data %>% as.data.frame() %>% write_tsv(path_modelo_tsv)
path_modelo_names_tsv = paste("saida_distancia_partidos/",tema,"_names",".tsv",sep="")
modelo@.Data %>% rownames() %>% as.data.frame() %>% write_tsv(path_modelo_names_tsv)
### Normaliza vetores
palavras_normalizadas <- modelo %>% apply(1,normaliza_vetor) %>% t() %>% as.VectorSpaceModel()
### Filtra palavras
## filtra palavras a partir de criterio
path = paste("./",train_file,sep="")
palavras_usadas <- palavras_mais_frequentes(path, 50)
palavras_usadas <- c(palavras_usadas[str_length(palavras_usadas) > MIN_TAMANHO], partidos)
palavras_normalizadas_usadas <- palavras_normalizadas[[palavras_usadas, average=F]]
### Distância entre par de palavras
### Para cada par de palavras do conjunto de palavras neutras, calcula a distancia entre elas.
par_palavras <- forma_par_palavras(palavras_normalizadas_usadas)
path_par_palavras <- paste("saida_distancia_partidos/par_palavras_",tema,".csv",sep="")
write_csv(par_palavras, path_par_palavras)
#par_palavras <- read_csv(path_par_palavras)
proximidade_par_palavras <- calcula_proximidade(par_palavras, modelo, palavras_normalizadas_usadas)
path_proximidade_par_palavras = paste("saida_distancia_partidos/par_palavras_proximidade_",tema,".csv",sep="")
write_csv(proximidade_par_palavras, path_proximidade_par_palavras)
#proximidade_par_palavras <- read_csv(path_proximidade_par_palavras)
palavras_neutras <- proximidade_par_palavras %>% filter(palavra_1 %in% entity & palavra_2 %in% entity)
### Similaridade entre pares de palavras
similaridade_palavras <- calcula_s_score(proximidade_par_palavras, palavras_normalizadas_usadas, referencia_1, referencia_2)
path_similaridade_par_palavras = paste("saida_distancia_partidos/par_palavras_similaridade_",tema,".csv",sep="")
write_csv(proximidade_par_palavras, path_similaridade_par_palavras)
### Direct bias
g <- (palavras_normalizadas_usadas[[referencia_1]] - palavras_normalizadas_usadas[[referencia_2]])
constant <- 1
direct_bias_words <- direct_bias_calculator(entity, g, constant, palavras_normalizadas_usadas)
direct_bias_value <- direct_bias_words %>% summarise(valor = abs(cosine_c) %>% mean())
### Direct bias graphic
# a coluna y esta sendo usada apenas para dispersar as palavras verticalmente e evitar a sobreposicao delas
direct_bias_words_graphic <- direct_bias_words %>% filter(!(entidade %in% c(referencia_1, referencia_2))) %>% mutate(y = sample(-9:9, n(), replace = T))
direct_bias_words_graphic %>% ggplot(aes(x=cosine_c, y=y, label=entidade)) + geom_text()
ggsave(paste(tema,".pdf",sep=""))
### Indirect bias
#entities <- data_frame(entidade = partidos)
#indirect_bias_psdb <- entities %>% rowwise() %>% mutate(indirect_bias = indirect_bias_calculator(entidade, "psdb", g, palavras_normalizadas_usadas))
return(list(modelo, direct_bias_value))
}
estadao_test <- direct_bias_detection(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers, analogias, candidatos, entity, pattern, noticias)
direct_bias_detection(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers, analogias, candidatos, entity, pattern, noticias)
b <- function(a){
print(a)
}
b("a")
direct_bias_detection <- function(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers = 300, analogias, candidatos, entity, pattern, noticias){
train_file <- paste("saida_distancia_partidos/",tema,".csv",sep="")
binary_file <- paste("saida_distancia_partidos/",tema,".bin",sep="")
noticias_tema %>% select(conteudo_processado) %>% write_csv(train_file)
modelo <- train_word2vec(train_file, threads = 8, vectors = n_layers)
### Regras que devem ser acertadas para validar embedding
verifica_analogias(binary_file, analogias, respostas)
### Cria tsv com embedding
path_modelo_tsv = paste("saida_distancia_partidos/",tema,".tsv",sep="")
modelo@.Data %>% as.data.frame() %>% write_tsv(path_modelo_tsv)
path_modelo_names_tsv = paste("saida_distancia_partidos/",tema,"_names",".tsv",sep="")
modelo@.Data %>% rownames() %>% as.data.frame() %>% write_tsv(path_modelo_names_tsv)
### Normaliza vetores
palavras_normalizadas <- modelo %>% apply(1,normaliza_vetor) %>% t() %>% as.VectorSpaceModel()
### Filtra palavras
## filtra palavras a partir de criterio
path = paste("./",train_file,sep="")
palavras_usadas <- palavras_mais_frequentes(path, 50)
palavras_usadas <- c(palavras_usadas[str_length(palavras_usadas) > MIN_TAMANHO], partidos)
palavras_normalizadas_usadas <- palavras_normalizadas[[palavras_usadas, average=F]]
### Distância entre par de palavras
### Para cada par de palavras do conjunto de palavras neutras, calcula a distancia entre elas.
par_palavras <- forma_par_palavras(palavras_normalizadas_usadas)
path_par_palavras <- paste("saida_distancia_partidos/par_palavras_",tema,".csv",sep="")
write_csv(par_palavras, path_par_palavras)
#par_palavras <- read_csv(path_par_palavras)
proximidade_par_palavras <- calcula_proximidade(par_palavras, modelo, palavras_normalizadas_usadas)
path_proximidade_par_palavras = paste("saida_distancia_partidos/par_palavras_proximidade_",tema,".csv",sep="")
write_csv(proximidade_par_palavras, path_proximidade_par_palavras)
#proximidade_par_palavras <- read_csv(path_proximidade_par_palavras)
palavras_neutras <- proximidade_par_palavras %>% filter(palavra_1 %in% entity & palavra_2 %in% entity)
### Similaridade entre pares de palavras
similaridade_palavras <- calcula_s_score(proximidade_par_palavras, palavras_normalizadas_usadas, referencia_1, referencia_2)
path_similaridade_par_palavras = paste("saida_distancia_partidos/par_palavras_similaridade_",tema,".csv",sep="")
write_csv(proximidade_par_palavras, path_similaridade_par_palavras)
### Direct bias
g <- (palavras_normalizadas_usadas[[referencia_1]] - palavras_normalizadas_usadas[[referencia_2]])
constant <- 1
direct_bias_words <- direct_bias_calculator(entity, g, constant, palavras_normalizadas_usadas)
direct_bias_value <- direct_bias_words %>% summarise(valor = abs(cosine_c) %>% mean())
### Direct bias graphic
# a coluna y esta sendo usada apenas para dispersar as palavras verticalmente e evitar a sobreposicao delas
direct_bias_words_graphic <- direct_bias_words %>% filter(!(entidade %in% c(referencia_1, referencia_2))) %>% mutate(y = sample(-9:9, n(), replace = T))
direct_bias_words_graphic %>% ggplot(aes(x=cosine_c, y=y, label=entidade)) + geom_text()
ggsave(paste(tema,".pdf",sep=""))
### Indirect bias
#entities <- data_frame(entidade = partidos)
#indirect_bias_psdb <- entities %>% rowwise() %>% mutate(indirect_bias = indirect_bias_calculator(entidade, "psdb", g, palavras_normalizadas_usadas))
return(list(modelo, direct_bias_value))
}
direct_bias_detection(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers, analogias, candidatos, entity, pattern, noticias)
direct_bias_detection <- function(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers = 300, analogias, candidatos, entity, pattern, noticias){
train_file <- paste("saida_distancia_partidos/",tema,".csv",sep="")
binary_file <- paste("saida_distancia_partidos/",tema,".bin",sep="")
noticias %>% select(conteudo_processado) %>% write_csv(train_file)
modelo <- train_word2vec(train_file, threads = 8, vectors = n_layers)
### Regras que devem ser acertadas para validar embedding
verifica_analogias(binary_file, analogias, respostas)
### Cria tsv com embedding
path_modelo_tsv = paste("saida_distancia_partidos/",tema,".tsv",sep="")
modelo@.Data %>% as.data.frame() %>% write_tsv(path_modelo_tsv)
path_modelo_names_tsv = paste("saida_distancia_partidos/",tema,"_names",".tsv",sep="")
modelo@.Data %>% rownames() %>% as.data.frame() %>% write_tsv(path_modelo_names_tsv)
### Normaliza vetores
palavras_normalizadas <- modelo %>% apply(1,normaliza_vetor) %>% t() %>% as.VectorSpaceModel()
### Filtra palavras
## filtra palavras a partir de criterio
path = paste("./",train_file,sep="")
palavras_usadas <- palavras_mais_frequentes(path, 50)
palavras_usadas <- c(palavras_usadas[str_length(palavras_usadas) > MIN_TAMANHO], partidos)
palavras_normalizadas_usadas <- palavras_normalizadas[[palavras_usadas, average=F]]
### Distância entre par de palavras
### Para cada par de palavras do conjunto de palavras neutras, calcula a distancia entre elas.
par_palavras <- forma_par_palavras(palavras_normalizadas_usadas)
path_par_palavras <- paste("saida_distancia_partidos/par_palavras_",tema,".csv",sep="")
write_csv(par_palavras, path_par_palavras)
#par_palavras <- read_csv(path_par_palavras)
proximidade_par_palavras <- calcula_proximidade(par_palavras, modelo, palavras_normalizadas_usadas)
path_proximidade_par_palavras = paste("saida_distancia_partidos/par_palavras_proximidade_",tema,".csv",sep="")
write_csv(proximidade_par_palavras, path_proximidade_par_palavras)
#proximidade_par_palavras <- read_csv(path_proximidade_par_palavras)
palavras_neutras <- proximidade_par_palavras %>% filter(palavra_1 %in% entity & palavra_2 %in% entity)
### Similaridade entre pares de palavras
similaridade_palavras <- calcula_s_score(proximidade_par_palavras, palavras_normalizadas_usadas, referencia_1, referencia_2)
path_similaridade_par_palavras = paste("saida_distancia_partidos/par_palavras_similaridade_",tema,".csv",sep="")
write_csv(proximidade_par_palavras, path_similaridade_par_palavras)
### Direct bias
g <- (palavras_normalizadas_usadas[[referencia_1]] - palavras_normalizadas_usadas[[referencia_2]])
constant <- 1
direct_bias_words <- direct_bias_calculator(entity, g, constant, palavras_normalizadas_usadas)
direct_bias_value <- direct_bias_words %>% summarise(valor = abs(cosine_c) %>% mean())
### Direct bias graphic
# a coluna y esta sendo usada apenas para dispersar as palavras verticalmente e evitar a sobreposicao delas
direct_bias_words_graphic <- direct_bias_words %>% filter(!(entidade %in% c(referencia_1, referencia_2))) %>% mutate(y = sample(-9:9, n(), replace = T))
direct_bias_words_graphic %>% ggplot(aes(x=cosine_c, y=y, label=entidade)) + geom_text()
ggsave(paste(tema,".pdf",sep=""))
### Indirect bias
#entities <- data_frame(entidade = partidos)
#indirect_bias_psdb <- entities %>% rowwise() %>% mutate(indirect_bias = indirect_bias_calculator(entidade, "psdb", g, palavras_normalizadas_usadas))
return(list(modelo, direct_bias_value))
}
a<-direct_bias_detection(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers, analogias, candidatos, entity, pattern, noticias)
source("../utils/mongo_utils.R")
source("../utils/utils.R")
source("../utils/embeddings_utils.R")
library("wordVectors")
library("readr")
### Importa base de dados
noticias <- get_todas_noticias_processadas()
noticias_estadao <- noticias %>% filter(subFonte == "ESTADAO")
tema = "eleicoes_2014_estadao_test"
limiar = 1.1
MIN_TAMANHO = 3
referencia_1 = "dilma"
referencia_2 = "aécio"
n_layers = 300
analogias <- c("pt psdb dilma", "pt pv dilma","pt prtb dilma","pt psol dilma","pt psb dilma","pt psdc dilma","psdb pv aécio","psdb prtb aécio","psdb psol aécio","psdb psb aécio","psdb psdc aécio","pv prtb jorge","pv psol jorge","pv psb jorge","pv psdc jorge","prtb psol fidelix","prtb psb fidelix","prtb psdc fidelix","psol psb luciana","psol psdc luciana","psb psdc marina","dilma aécio rousseff","campos psb aécio","pt psdb petista")
respostas <- c("aécio","jorge","fidelix","luciana","marina","eymael","jorge","fidelix","luciana","marina","eymael","fidelix","luciana","marina","eymael","luciana","marina","eymael","marina","eymael","eymael","neves","psdb","tucano")
partidos <- c("pmdb","ptb","pdt","pt","dem ","psb","psdb","ptc","psc","pmn","prp","pps","pv","pp","pstu","pcb","prtb","phs","psdc","pco","ptn","psl","prb","psol","ppl","pros","psd |psd[.]"," sd |sd[.]") #,"pr","pen", "pcdob", "ptdob"
candidatos <- c("dilma","aécio","levy","marina silva","luciana genro","eduardo jorge","josé maria","pastor everaldo", "iasi","eymael","rui costa","eduardo campos")
entity <- c(candidatos, partidos)
pattern <- paste(entity, collapse = "|")
noticias <- noticias_estadao %>% filter(timestamp >= "2014-12-01" & timestamp <= "2014-12-31") %>% noticias_tema(pattern, "titulo")
direct_bias_detection <- function(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers = 300, analogias, candidatos, entity, pattern, noticias){
train_file <- paste("saida_distancia_partidos/",tema,".csv",sep="")
binary_file <- paste("saida_distancia_partidos/",tema,".bin",sep="")
noticias %>% select(conteudo_processado) %>% write_csv(train_file)
modelo <- train_word2vec(train_file, threads = 8, vectors = n_layers)
### Regras que devem ser acertadas para validar embedding
verifica_analogias(binary_file, analogias, respostas)
### Cria tsv com embedding
path_modelo_tsv = paste("saida_distancia_partidos/",tema,".tsv",sep="")
modelo@.Data %>% as.data.frame() %>% write_tsv(path_modelo_tsv)
path_modelo_names_tsv = paste("saida_distancia_partidos/",tema,"_names",".tsv",sep="")
modelo@.Data %>% rownames() %>% as.data.frame() %>% write_tsv(path_modelo_names_tsv)
### Normaliza vetores
palavras_normalizadas <- modelo %>% apply(1,normaliza_vetor) %>% t() %>% as.VectorSpaceModel()
### Filtra palavras
## filtra palavras a partir de criterio
path = paste("./",train_file,sep="")
palavras_usadas <- palavras_mais_frequentes(path, 50)
palavras_usadas <- c(palavras_usadas[str_length(palavras_usadas) > MIN_TAMANHO], partidos)
palavras_normalizadas_usadas <- palavras_normalizadas[[palavras_usadas, average=F]]
### Distância entre par de palavras
### Para cada par de palavras do conjunto de palavras neutras, calcula a distancia entre elas.
par_palavras <- forma_par_palavras(palavras_normalizadas_usadas)
path_par_palavras <- paste("saida_distancia_partidos/par_palavras_",tema,".csv",sep="")
write_csv(par_palavras, path_par_palavras)
#par_palavras <- read_csv(path_par_palavras)
proximidade_par_palavras <- calcula_proximidade(par_palavras, modelo, palavras_normalizadas_usadas)
path_proximidade_par_palavras = paste("saida_distancia_partidos/par_palavras_proximidade_",tema,".csv",sep="")
write_csv(proximidade_par_palavras, path_proximidade_par_palavras)
#proximidade_par_palavras <- read_csv(path_proximidade_par_palavras)
palavras_neutras <- proximidade_par_palavras %>% filter(palavra_1 %in% entity & palavra_2 %in% entity)
### Similaridade entre pares de palavras
similaridade_palavras <- calcula_s_score(proximidade_par_palavras, palavras_normalizadas_usadas, referencia_1, referencia_2)
path_similaridade_par_palavras = paste("saida_distancia_partidos/par_palavras_similaridade_",tema,".csv",sep="")
write_csv(proximidade_par_palavras, path_similaridade_par_palavras)
### Direct bias
g <- (palavras_normalizadas_usadas[[referencia_1]] - palavras_normalizadas_usadas[[referencia_2]])
constant <- 1
direct_bias_words <- direct_bias_calculator(entity, g, constant, palavras_normalizadas_usadas)
direct_bias_value <- direct_bias_words %>% summarise(valor = abs(cosine_c) %>% mean())
### Direct bias graphic
# a coluna y esta sendo usada apenas para dispersar as palavras verticalmente e evitar a sobreposicao delas
direct_bias_words_graphic <- direct_bias_words %>% filter(!(entidade %in% c(referencia_1, referencia_2))) %>% mutate(y = sample(-9:9, n(), replace = T))
direct_bias_words_graphic %>% ggplot(aes(x=cosine_c, y=y, label=entidade)) + geom_text()
ggsave(paste(tema,".pdf",sep=""))
### Indirect bias
#entities <- data_frame(entidade = partidos)
#indirect_bias_psdb <- entities %>% rowwise() %>% mutate(indirect_bias = indirect_bias_calculator(entidade, "psdb", g, palavras_normalizadas_usadas))
return(list(modelo, direct_bias_value))
}
a<-direct_bias_detection(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers, analogias, candidatos, entity, pattern, noticias)
a[[2]]
a[[1]]
noticias <- noticias_estadao %>% filter(timestamp >= "2014-06-01" & timestamp <= "2014-07-31") %>% noticias_tema(pattern, "titulo")
a<-direct_bias_detection(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers, analogias, candidatos, entity, pattern, noticias)
a[[1]][["dilma"]]
a[[1]][["aécio"]]
a[[1]][["marina"]]
a[[1]][["aeefd"]]
a[[1]][["pt"]]
direct_bias_detection <- function(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers = 300, analogias, candidatos, entity, pattern, noticias){
train_file <- paste("saida_distancia_partidos/",tema,".csv",sep="")
binary_file <- paste("saida_distancia_partidos/",tema,".bin",sep="")
noticias %>% select(conteudo_processado) %>% write_csv(train_file)
modelo <- train_word2vec(train_file, threads = 8, vectors = n_layers)
### Regras que devem ser acertadas para validar embedding
verifica_analogias(binary_file, analogias, respostas)
### Cria tsv com embedding
path_modelo_tsv = paste("saida_distancia_partidos/",tema,".tsv",sep="")
modelo@.Data %>% as.data.frame() %>% write_tsv(path_modelo_tsv)
path_modelo_names_tsv = paste("saida_distancia_partidos/",tema,"_names",".tsv",sep="")
modelo@.Data %>% rownames() %>% as.data.frame() %>% write_tsv(path_modelo_names_tsv)
### Normaliza vetores
palavras_normalizadas <- modelo %>% apply(1,normaliza_vetor) %>% t() %>% as.VectorSpaceModel()
### Filtra palavras
## filtra palavras a partir de criterio
path = paste("./",train_file,sep="")
palavras_usadas <- palavras_mais_frequentes(path, 50)
palavras_usadas <- c(palavras_usadas[str_length(palavras_usadas) > MIN_TAMANHO], partidos)
palavras_normalizadas_usadas <- palavras_normalizadas[[palavras_usadas, average=F]]
### Distância entre par de palavras
### Para cada par de palavras do conjunto de palavras neutras, calcula a distancia entre elas.
par_palavras <- forma_par_palavras(palavras_normalizadas_usadas)
path_par_palavras <- paste("saida_distancia_partidos/par_palavras_",tema,".csv",sep="")
write_csv(par_palavras, path_par_palavras)
#par_palavras <- read_csv(path_par_palavras)
proximidade_par_palavras <- calcula_proximidade(par_palavras, modelo, palavras_normalizadas_usadas)
path_proximidade_par_palavras = paste("saida_distancia_partidos/par_palavras_proximidade_",tema,".csv",sep="")
write_csv(proximidade_par_palavras, path_proximidade_par_palavras)
#proximidade_par_palavras <- read_csv(path_proximidade_par_palavras)
palavras_neutras <- proximidade_par_palavras %>% filter(palavra_1 %in% entity & palavra_2 %in% entity)
print(palavras_neutras)
### Similaridade entre pares de palavras
similaridade_palavras <- calcula_s_score(proximidade_par_palavras, palavras_normalizadas_usadas, referencia_1, referencia_2)
path_similaridade_par_palavras = paste("saida_distancia_partidos/par_palavras_similaridade_",tema,".csv",sep="")
write_csv(similaridade_palavras, path_similaridade_par_palavras)
### Direct bias
g <- (palavras_normalizadas_usadas[[referencia_1]] - palavras_normalizadas_usadas[[referencia_2]])
constant <- 1
direct_bias_words <- direct_bias_calculator(entity, g, constant, palavras_normalizadas_usadas)
direct_bias_value <- direct_bias_words %>% summarise(valor = abs(cosine_c) %>% mean())
### Direct bias graphic
# a coluna y esta sendo usada apenas para dispersar as palavras verticalmente e evitar a sobreposicao delas
direct_bias_words_graphic <- direct_bias_words %>% filter(!(entidade %in% c(referencia_1, referencia_2))) %>% mutate(y = sample(-9:9, n(), replace = T))
direct_bias_words_graphic %>% ggplot(aes(x=cosine_c, y=y, label=entidade)) + geom_text()
ggsave(paste(tema,".pdf",sep=""))
### Indirect bias
#entities <- data_frame(entidade = partidos)
#indirect_bias_psdb <- entities %>% rowwise() %>% mutate(indirect_bias = indirect_bias_calculator(entidade, "psdb", g, palavras_normalizadas_usadas))
return(list(modelo, direct_bias_value))
}
a<-direct_bias_detection(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers, analogias, candidatos, entity, pattern, noticias)
direct_bias_detection <- function(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers = 300, analogias, candidatos, entity, pattern, noticias){
train_file <- paste("saida_distancia_partidos/",tema,".csv",sep="")
binary_file <- paste("saida_distancia_partidos/",tema,".bin",sep="")
noticias %>% select(conteudo_processado) %>% write_csv(train_file)
modelo <- train_word2vec(train_file, threads = 8, vectors = n_layers)
### Regras que devem ser acertadas para validar embedding
verifica_analogias(binary_file, analogias, respostas)
### Cria tsv com embedding
path_modelo_tsv = paste("saida_distancia_partidos/",tema,".tsv",sep="")
modelo@.Data %>% as.data.frame() %>% write_tsv(path_modelo_tsv)
path_modelo_names_tsv = paste("saida_distancia_partidos/",tema,"_names",".tsv",sep="")
modelo@.Data %>% rownames() %>% as.data.frame() %>% write_tsv(path_modelo_names_tsv)
### Normaliza vetores
palavras_normalizadas <- modelo %>% apply(1,normaliza_vetor) %>% t() %>% as.VectorSpaceModel()
### Filtra palavras
## filtra palavras a partir de criterio
path = paste("./",train_file,sep="")
palavras_usadas <- palavras_mais_frequentes(path, 50)
palavras_usadas <- c(palavras_usadas[str_length(palavras_usadas) > MIN_TAMANHO], partidos)
palavras_normalizadas_usadas <- palavras_normalizadas[[palavras_usadas, average=F]]
### Distância entre par de palavras
### Para cada par de palavras do conjunto de palavras neutras, calcula a distancia entre elas.
par_palavras <- forma_par_palavras(palavras_normalizadas_usadas)
path_par_palavras <- paste("saida_distancia_partidos/par_palavras_",tema,".csv",sep="")
write_csv(par_palavras, path_par_palavras)
#par_palavras <- read_csv(path_par_palavras)
proximidade_par_palavras <- calcula_proximidade(par_palavras, modelo, palavras_normalizadas_usadas)
path_proximidade_par_palavras = paste("saida_distancia_partidos/par_palavras_proximidade_",tema,".csv",sep="")
write_csv(proximidade_par_palavras, path_proximidade_par_palavras)
#proximidade_par_palavras <- read_csv(path_proximidade_par_palavras)
palavras_neutras <- proximidade_par_palavras %>% filter(palavra_1 %in% entity & palavra_2 %in% entity)
### Similaridade entre pares de palavras
similaridade_palavras <- calcula_s_score(proximidade_par_palavras, palavras_normalizadas_usadas, referencia_1, referencia_2)
path_similaridade_par_palavras = paste("saida_distancia_partidos/par_palavras_similaridade_",tema,".csv",sep="")
write_csv(similaridade_palavras, path_similaridade_par_palavras)
### Direct bias
g <- (palavras_normalizadas_usadas[[referencia_1]] - palavras_normalizadas_usadas[[referencia_2]])
constant <- 1
direct_bias_words <- direct_bias_calculator(entity, g, constant, palavras_normalizadas_usadas)
direct_bias_value <- direct_bias_words %>% summarise(valor = abs(cosine_c) %>% mean())
### Direct bias graphic
# a coluna y esta sendo usada apenas para dispersar as palavras verticalmente e evitar a sobreposicao delas
direct_bias_words_graphic <- direct_bias_words %>% filter(!(entidade %in% c(referencia_1, referencia_2))) %>% mutate(y = sample(-9:9, n(), replace = T))
direct_bias_words_graphic %>% ggplot(aes(x=cosine_c, y=y, label=entidade)) + geom_text()
ggsave(paste(tema,".pdf",sep=""))
### Indirect bias
#entities <- data_frame(entidade = partidos)
#indirect_bias_psdb <- entities %>% rowwise() %>% mutate(indirect_bias = indirect_bias_calculator(entidade, "psdb", g, palavras_normalizadas_usadas))
print(direct_bias_value)
print(direct_bias_words)
return(list(modelo, direct_bias_words, direct_bias_value))
}
a[[1]]
a[[2]]
a[[3]]
direct_bias_detection <- function(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers = 300, analogias, candidatos, entity, pattern, noticias){
train_file <- paste("saida_distancia_partidos/",tema,".csv",sep="")
binary_file <- paste("saida_distancia_partidos/",tema,".bin",sep="")
noticias %>% select(conteudo_processado) %>% write_csv(train_file)
modelo <- train_word2vec(train_file, threads = 8, vectors = n_layers)
### Regras que devem ser acertadas para validar embedding
verifica_analogias(binary_file, analogias, respostas)
### Cria tsv com embedding
path_modelo_tsv = paste("saida_distancia_partidos/",tema,".tsv",sep="")
modelo@.Data %>% as.data.frame() %>% write_tsv(path_modelo_tsv)
path_modelo_names_tsv = paste("saida_distancia_partidos/",tema,"_names",".tsv",sep="")
modelo@.Data %>% rownames() %>% as.data.frame() %>% write_tsv(path_modelo_names_tsv)
### Normaliza vetores
palavras_normalizadas <- modelo %>% apply(1,normaliza_vetor) %>% t() %>% as.VectorSpaceModel()
### Filtra palavras
## filtra palavras a partir de criterio
path = paste("./",train_file,sep="")
palavras_usadas <- palavras_mais_frequentes(path, 50)
palavras_usadas <- c(palavras_usadas[str_length(palavras_usadas) > MIN_TAMANHO], partidos)
palavras_normalizadas_usadas <- palavras_normalizadas[[palavras_usadas, average=F]]
### Distância entre par de palavras
### Para cada par de palavras do conjunto de palavras neutras, calcula a distancia entre elas.
par_palavras <- forma_par_palavras(palavras_normalizadas_usadas)
path_par_palavras <- paste("saida_distancia_partidos/par_palavras_",tema,".csv",sep="")
write_csv(par_palavras, path_par_palavras)
#par_palavras <- read_csv(path_par_palavras)
proximidade_par_palavras <- calcula_proximidade(par_palavras, modelo, palavras_normalizadas_usadas)
path_proximidade_par_palavras = paste("saida_distancia_partidos/par_palavras_proximidade_",tema,".csv",sep="")
write_csv(proximidade_par_palavras, path_proximidade_par_palavras)
#proximidade_par_palavras <- read_csv(path_proximidade_par_palavras)
palavras_neutras <- proximidade_par_palavras %>% filter(palavra_1 %in% entity & palavra_2 %in% entity)
### Similaridade entre pares de palavras
similaridade_palavras <- calcula_s_score(proximidade_par_palavras, palavras_normalizadas_usadas, referencia_1, referencia_2)
path_similaridade_par_palavras = paste("saida_distancia_partidos/par_palavras_similaridade_",tema,".csv",sep="")
write_csv(similaridade_palavras, path_similaridade_par_palavras)
### Direct bias
g <- (palavras_normalizadas_usadas[[referencia_1]] - palavras_normalizadas_usadas[[referencia_2]])
constant <- 1
direct_bias_words <- direct_bias_calculator(entity, g, constant, palavras_normalizadas_usadas)
direct_bias_value <- direct_bias_words %>% summarise(valor = abs(cosine_c) %>% mean())
### Direct bias graphic
# a coluna y esta sendo usada apenas para dispersar as palavras verticalmente e evitar a sobreposicao delas
direct_bias_words_graphic <- direct_bias_words %>% filter(!(entidade %in% c(referencia_1, referencia_2))) %>% mutate(y = sample(-9:9, n(), replace = T))
direct_bias_words_graphic %>% ggplot(aes(x=cosine_c, y=y, label=entidade)) + geom_text()
ggsave(paste(tema,".pdf",sep=""))
### Indirect bias
#entities <- data_frame(entidade = partidos)
#indirect_bias_psdb <- entities %>% rowwise() %>% mutate(indirect_bias = indirect_bias_calculator(entidade, "psdb", g, palavras_normalizadas_usadas))
print(direct_bias_value)
print(direct_bias_words)
return(list(modelo, direct_bias_words, direct_bias_value))
}
a<-direct_bias_detection(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers, analogias, candidatos, entity, pattern, noticias)
a[[1]]
a[[2]]
a[[3]]
source("../utils/mongo_utils.R")
source("../utils/utils.R")
source("../utils/embeddings_utils.R")
library("wordVectors")
library("readr")
### Importa base de dados
noticias <- get_todas_noticias_processadas()
noticias_estadao <- noticias %>% filter(subFonte == "ESTADAO")
tema = "eleicoes_2014_estadao_test"
limiar = 1.1
MIN_TAMANHO = 3
referencia_1 = "dilma"
referencia_2 = "aécio"
n_layers = 300
analogias <- c("pt psdb dilma", "pt pv dilma","pt prtb dilma","pt psol dilma","pt psb dilma","pt psdc dilma","psdb pv aécio","psdb prtb aécio","psdb psol aécio","psdb psb aécio","psdb psdc aécio","pv prtb jorge","pv psol jorge","pv psb jorge","pv psdc jorge","prtb psol fidelix","prtb psb fidelix","prtb psdc fidelix","psol psb luciana","psol psdc luciana","psb psdc marina","dilma aécio rousseff","campos psb aécio","pt psdb petista")
respostas <- c("aécio","jorge","fidelix","luciana","marina","eymael","jorge","fidelix","luciana","marina","eymael","fidelix","luciana","marina","eymael","luciana","marina","eymael","marina","eymael","eymael","neves","psdb","tucano")
partidos <- c("pmdb","ptb","pdt","pt","dem ","psb","psdb","ptc","psc","pmn","prp","pps","pv","pp","pstu","pcb","prtb","phs","psdc","pco","ptn","psl","prb","psol","ppl","pros","psd |psd[.]"," sd |sd[.]") #,"pr","pen", "pcdob", "ptdob"
candidatos <- c("dilma","aécio","levy","marina silva","luciana genro","eduardo jorge","josé maria","pastor everaldo", "iasi","eymael","rui costa","eduardo campos")
entity <- c(candidatos, partidos)
pattern <- paste(entity, collapse = "|")
noticias <- noticias_estadao %>% filter(timestamp >= "2014-06-01" & timestamp <= "2014-07-31") %>% noticias_tema(pattern, "titulo")
direct_bias_detection <- function(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers = 300, analogias, candidatos, entity, pattern, noticias){
train_file <- paste("saida_distancia_partidos/",tema,".csv",sep="")
binary_file <- paste("saida_distancia_partidos/",tema,".bin",sep="")
noticias %>% select(conteudo_processado) %>% write_csv(train_file)
modelo <- train_word2vec(train_file, threads = 8, vectors = n_layers)
### Regras que devem ser acertadas para validar embedding
verifica_analogias(binary_file, analogias, respostas)
### Cria tsv com embedding
path_modelo_tsv = paste("saida_distancia_partidos/",tema,".tsv",sep="")
modelo@.Data %>% as.data.frame() %>% write_tsv(path_modelo_tsv)
path_modelo_names_tsv = paste("saida_distancia_partidos/",tema,"_names",".tsv",sep="")
modelo@.Data %>% rownames() %>% as.data.frame() %>% write_tsv(path_modelo_names_tsv)
### Normaliza vetores
palavras_normalizadas <- modelo %>% apply(1,normaliza_vetor) %>% t() %>% as.VectorSpaceModel()
### Filtra palavras
## filtra palavras a partir de criterio
path = paste("./",train_file,sep="")
palavras_usadas <- palavras_mais_frequentes(path, 50)
palavras_usadas <- c(palavras_usadas[str_length(palavras_usadas) > MIN_TAMANHO], partidos)
palavras_normalizadas_usadas <- palavras_normalizadas[[palavras_usadas, average=F]]
### Distância entre par de palavras
### Para cada par de palavras do conjunto de palavras neutras, calcula a distancia entre elas.
par_palavras <- forma_par_palavras(palavras_normalizadas_usadas)
path_par_palavras <- paste("saida_distancia_partidos/par_palavras_",tema,".csv",sep="")
write_csv(par_palavras, path_par_palavras)
#par_palavras <- read_csv(path_par_palavras)
proximidade_par_palavras <- calcula_proximidade(par_palavras, modelo, palavras_normalizadas_usadas)
path_proximidade_par_palavras = paste("saida_distancia_partidos/par_palavras_proximidade_",tema,".csv",sep="")
write_csv(proximidade_par_palavras, path_proximidade_par_palavras)
#proximidade_par_palavras <- read_csv(path_proximidade_par_palavras)
palavras_neutras <- proximidade_par_palavras %>% filter(palavra_1 %in% entity & palavra_2 %in% entity)
### Similaridade entre pares de palavras
similaridade_palavras <- calcula_s_score(proximidade_par_palavras, palavras_normalizadas_usadas, referencia_1, referencia_2)
path_similaridade_par_palavras = paste("saida_distancia_partidos/par_palavras_similaridade_",tema,".csv",sep="")
write_csv(similaridade_palavras, path_similaridade_par_palavras)
### Direct bias
g <- (palavras_normalizadas_usadas[[referencia_1]] - palavras_normalizadas_usadas[[referencia_2]])
constant <- 1
direct_bias_words <- direct_bias_calculator(entity, g, constant, palavras_normalizadas_usadas)
direct_bias_value <- direct_bias_words %>% summarise(valor = abs(cosine_c) %>% mean())
### Direct bias graphic
# a coluna y esta sendo usada apenas para dispersar as palavras verticalmente e evitar a sobreposicao delas
direct_bias_words_graphic <- direct_bias_words %>% filter(!(entidade %in% c(referencia_1, referencia_2))) %>% mutate(y = sample(-9:9, n(), replace = T))
direct_bias_words_graphic %>% ggplot(aes(x=cosine_c, y=y, label=entidade)) + geom_text()
ggsave(paste(tema,".pdf",sep=""))
### Indirect bias
#entities <- data_frame(entidade = partidos)
#indirect_bias_psdb <- entities %>% rowwise() %>% mutate(indirect_bias = indirect_bias_calculator(entidade, "psdb", g, palavras_normalizadas_usadas))
print(direct_bias_value)
print(direct_bias_words)
return(list(modelo, direct_bias_words, direct_bias_value))
}
a<-direct_bias_detection(tema, limiar, MIN_TAMANHO, referencia_1, referencia_2, n_layers, analogias, candidatos, entity, pattern, noticias)
