---
title: "distancia_partidos"
author: "Allan Sales"
date: "9 de outubro de 2017"
output: html_document
---

## Formas de avaliar word embeddings

Relatedness (relacionamento): A correlação entre a similaridade do cosseno entre pares de palavras e os scores humanos para os mesmos pares de palavras devem ser altos.

Analogia: Verificar a veracidade de algumas analogias que espera-se previamente que necessitam estar corretas. Por exemplo, um indício que os word embeddings estão treinados corretamente é que as analogias abaixo sejam verdadeiras:

pt -> petista, psdb -> tucano ##ok
dilma -> rousseff, aécio -> neves ##ok
dilma -> petista, aécio -> tucano ##ok
pt -> dilma, psdb -> aécio ##ok

Categorização: Dividir as palavras em grupos e medir a pureza dos grupos. Medir quão faz sentido as palavras pertencerem a aquele grupo.

Preferência seletiva: Verificar quão típico é um substantivo ser recomendado a um verbo e quanto um verbo é recomendado a um substantivo. Por exemplo, 'pessoas comem' é uma frase comum mas 'comem pessoas' nem tanto. 

Coerência: Verificar quão semanticamente similares são palavras vizinhas em pequenos grupos de palavras. Bons word embeddings devem retornar, para uma consulta de palavra, outras semanticamente parecidas, então em um grupo pequeno de palavras (3 ou 4), ao se pesquisar por uma palavra, as outras do grupo, devem ser semanticamente próximas.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("../utils/mongo_utils.R")
source("../utils/utils.R")
library("wordVectors")
library("readr")
library("rword2vec")
```

### Importa base de dados
```{r}
noticias <- get_todas_noticias_processadas()
noticias_estadao <- noticias %>% filter(subFonte == "ESTADAO")
noticias_folha <- noticias %>% filter(subFonte == "FOLHASP")
noticias_g1 <- noticias %>% filter(subFonte == "G1")
```

### Noticias eleicao
```{r}
partidos <- c("pmdb","ptb","pdt","pt","dem ","psb","psdb","ptc","psc","pmn","prp","pps","pv","pp","pstu","pcb","prtb","phs","psdc","pco","ptn","psl","prb","psol","ppl","pros","psd |psd[.]"," sd |sd[.]") #,"pr","pen", "pcdob", "ptdob"
candidatos <- c("dilma","aécio","levy","marina","genro","eduardo jorge","josé maria","pastor everaldo", "iasi","eymael","rui costa","eduardo campos")

entity <- c(candidatos, partidos)
pattern <- paste(entity, collapse = "|")

noticias_estadao_tema <- noticias_estadao %>% filter(timestamp >= "2014-05-30", ano == 2014) %>% noticias_tema(pattern, "titulo")
```

### Cria embeddings
```{r}
tema = "eleicoes_2014_jun"
train_file <- paste(tema,".csv",sep="")
binary_file <- paste(tema,".bin",sep="")
n.layers = 300
noticias_estadao_tema %>% select(conteudo_processado) %>% write_csv(train_file)
#modelo <- train_word2vec(train_file, threads = 4, vectors = n.layers)
modelo <- read.binary.vectors(binary_file)
```

### Regras que devem ser acertadas para validar embedding
```{r}
word_analogy(file_name = binary_file, search_words = "pt psdb petista")
word_analogy(file_name = binary_file, search_words = "dilma aécio rousseff")
word_analogy(file_name = binary_file, search_words = "dilma aécio petista")
word_analogy(file_name = binary_file, search_words = "pt psdb dilma")
word_analogy(file_name = binary_file, search_words = "campos psb aécio")
word_analogy(file_name = binary_file, search_words = "marina psb aécio")
word_analogy(file_name = binary_file, search_words = "aécio psdb eymael")
word_analogy(file_name = binary_file, search_words = "dilma pt eymael")
word_analogy(file_name = binary_file, search_words = "dilma pt fidelix")
word_analogy(file_name = binary_file, search_words = "genro psol fidelix")
word_analogy(file_name = binary_file, search_words = "fidelix prtb jorge")
```

### Cria tsv com embedding
```{r}
path_modelo_tsv = paste(tema,".tsv",sep="")
modelo@.Data %>% as.data.frame() %>% write_tsv(path_modelo_tsv)

path_modelo_names_tsv = paste(tema,"_names",".tsv",sep="")
modelo@.Data %>% rownames() %>% as.data.frame() %>% write_tsv(path_modelo_names_tsv)
```

### Filtra palavras 
```{r}
## filtra palavras a partir de criterio
path = paste("./",train_file,sep="")
eleicao_tm <- scan(path, what = "character")

threshold <- 50
palavras_freq <- table(eleicao_tm) %>% data.frame() %>% filter(Freq >= threshold)
palavras_usadas <- palavras_freq %>% .$eleicao_tm %>% as.character()
```

### Vetores de entidades
```{r}
vetores_entidade_estadao <- modelo[[palavras_usadas, average=F]]
```

### Normaliza vetores
```{r}
# normaliza vetores
normaliza_vetor <- function(vetor_palavra){
  norma <- vetor_palavra %>% pracma::Norm()
  vetor_normalizado <- vetor_palavra/norma
  return(vetor_normalizado)
}

palavras_normalizadas <- vetores_entidade_estadao@.Data %>% apply(1,normaliza_vetor) %>% t()
```

### Distância entre par de palavras
Para cada par de palavras do conjunto de palavras neutras, calcula a distancia entre elas.
```{r}
# calcula a norma da diferença entre duas palavras
calcula_proximidade <- function(modelo, palavra_1, palavra_2){
  palavra_1 <- palavra_1 %>% as.character()
  palavra_2 <- palavra_2 %>% as.character()
  embed_1 <- modelo[[palavra_1]]
  embed_2 <- modelo[[palavra_2]]
  dif_norma <- (embed_1 - embed_2) %>% pracma::Norm()
  return(dif_norma)
}

#par_palavras <- palavras_normalizadas %>% rownames() %>% combn(2) %>% t() %>% as.data.frame() %>% rename(palavra_1 = V1, palavra_2 = V2)
path_par_palavras = paste("saida_distancia_partidos/par_palavras_",tema,".csv",sep="")
#write_csv(par_palavras, path_par_palavras)
par_palavras <- read_csv(path_par_palavras)

#proximidade_par_palavras <- par_palavras %>% rowwise() %>% mutate(prox = calcula_proximidade(modelo, palavra_1, palavra_2))
#inverso <- proximidade_par_palavras %>% select(palavra_1 = palavra_2, palavra_2 = palavra_1, prox)
#proximidade_par_palavras <- bind_rows(proximidade_par_palavras, inverso)
#path_proximidade_par_palavras = paste("saida_distancia_partidos/proximidade_palavras_",tema,".csv",sep="")
#write_csv(proximidade_par_palavras, path_proximidade_par_palavras)
proximidade_par_palavras <- read_csv(path_proximidade_par_palavras)
```

```{r}
palavras_neutras <- proximidade_par_palavras %>% filter(palavra_1 %in% entity & palavra_2 %in% entity)
```


### Similaridade entre pares de palavras
```{r}
# calcula o cosseno entre a-b e x-y
s_score <- function(palavra_1, palavra_2, referencia_1, referencia_2, word_embedding){
  palavra_1 <- palavra_1 %>% as.character()
  palavra_2 <- palavra_2 %>% as.character()
  x <- word_embedding[[palavra_1]]
  y <- word_embedding[[palavra_2]]
  
  a <- word_embedding[[referencia_1]]
  b <- word_embedding[[referencia_2]]
  cos <- cosineSimilarity(x-y, a-b)
}

# limiar de 1 porque eh o cossendo de pi/3 (que implica da distancia entre as palavras serem menores entre si que entre elas e a origem)
limiar = 1 #%>% filter(prox <= limiar)

similaridade_palavras <- palavras_neutras %>% rowwise() %>% mutate(similaridade_cos = s_score(palavra_1, palavra_2, "dilma", "aécio", modelo))
similaridade_palavras <- similaridade_palavras %>% arrange(-similaridade_cos, prox)
```

### Direct bias
```{r}
g <- modelo[["dilma"]] - modelo[["aécio"]]
constant <- 1

direct_bias_calculator <- function(entities, g, c, word_embedding){
  entities <- data_frame(entidade = entities)
  entities_bias <- entities %>% rowwise() %>% mutate(cosine_c = cosineSimilarity(word_embedding[[entidade]], g) %>% .**c)
  direct_bias_weights <- entities_bias %>% na.omit()
  return(direct_bias_weights)
}

direct_bias_words <- direct_bias_calculator(entity, g, constant, modelo)

direct_bias_value <- direct_bias_words %>% summarise(valor = abs(cosine_c) %>% mean())
```

### Direct bias graphic
```{r}
direct_bias_words_graphic <- direct_bias_words %>% mutate(y = sample(-9:9, n(), replace = T))

direct_bias_words_graphic %>% ggplot(aes(x=cosine_c, y=y, label=entidade)) + geom_text()
```


### Indirect bias
```{r}

## TODO
multiply <- function(x, y){
  return(x*y)
}

wg_calculator <- function(entidade, g, word_embedding){
  wg <- (entidade %*% t(g)) %>% as.numeric() %>% multiply(g)
  return(wg)
}

wp_calculator <- function(entidade, g){
  wg <- wg_calculator(entidade, g)
  wp <- entidade - wg
  return(wp)
}

indirect_bias_calculator <- function(entidade_1, entidade_2, g, word_embedding){
  entidade_1 <- word_embedding[[entidade_1]]
  entidade_2 <- word_embedding[[entidade_2]]
  
  inner_product <- entidade_1 %*% t(entidade_2)
  
  wp <- wp_calculator(entidade_1, g)
  vp <- wp_calculator(entidade_2, g)
  bias_influence <- (wp %*% t(vp))/(Norm(wp) * Norm(vp))

  indirect_bias <- (inner_product - bias_influence)/inner_product
}

entities <- data_frame(entidade = partidos)
indirect_bias <- entities %>% rowwise() %>% mutate(indirect_bias = indirect_bias_calculator(entidade, "pt", g, tema_z_estadao))

```